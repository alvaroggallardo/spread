"""
Scraper para eventos - Laboral Centro Arte.
"""

from app.scrapers.base import *

def get_events_laboral_actividades():
    from urllib.parse import urljoin, quote_plus
    import re

    base = "https://laboralcentrodearte.org"
    url = f"{base}/es/actividades/"
    events = []

    try:
        res = requests.get(url, timeout=12)
        if res.status_code != 200:
            print(f"âŒ Error al cargar la pÃ¡gina: {res.status_code}")
            return []

        soup = BeautifulSoup(res.content, "html.parser")

        items = soup.select("ul.exhibition-block__items li.exhibition-block__item")
        print(f"ğŸ“¦ Encontrados {len(items)} eventos (Laboral)")

        for idx, li in enumerate(items):
            a = li.select_one("a[href]")
            if not a:
                continue

            raw_link = a.get("href", "").strip()
            link = urljoin(base, raw_link)

            # TÃ­tulo
            title_el = li.select_one("h4.exhibition-block__item-name")
            title_text = title_el.get_text(strip=True) if title_el else "Sin tÃ­tulo"
            title = f"ğŸ–¼ï¸ {title_text}"

            # Fecha (ej: "21 Septiembre 2025")
            date_el = li.select_one("div.exhibition-block__item-dates")
            date_text = date_el.get_text(" ", strip=True) if date_el else ""
            date_text = re.sub(r"\s+", " ", date_text)

            start_date = end_date = None
            if date_text:
                # La pÃ¡gina suele dar fecha Ãºnica; si alguna vez diera rango, intentamos dividirlo
                parts = re.split(r"\s+(?:al|a|â€“|â€”|-)\s+", date_text, maxsplit=1, flags=re.IGNORECASE)
                left = parts[0].strip()
                right = parts[1].strip() if len(parts) > 1 else left

                start_date = dateparser.parse(left, languages=["es"], settings={"DATE_ORDER": "DMY"})
                end_date = dateparser.parse(right, languages=["es"], settings={"DATE_ORDER": "DMY"})

            # UbicaciÃ³n fija del centro (el listado no trae direcciÃ³n concreta)
            location = "LABoral Centro de Arte, GijÃ³n"
            lugar = f'=HYPERLINK("https://www.google.com/maps/search/?api=1&query={quote_plus(location)}", "{location}")'

            # âœ… Evitar duplicados por enlace y fecha de inicio
            if any(ev["link"] == link and ev["fecha"] == start_date for ev in events):
                print(f"ğŸ” Duplicado saltado: {title_text}")
                continue

            disciplina = inferir_disciplina(title_text)

            events.append({
                "fuente": "LaboralCentroDeArte",
                "evento": title,
                "fecha": start_date,
                "fecha_fin": end_date,
                "hora": "",
                "lugar": lugar,
                "link": link,
                "disciplina": disciplina
            })
            print(f"âœ… [{idx}] AÃ±adido: {title_text}")

        print(f"ğŸ‰ Total eventos Laboral: {len(events)}")
        return events

    except Exception as e:
        print(f"âŒ Error en get_events_laboral_actividades: {e}")
        return []


# --------------------------
# Scraping Asturias Convivencias
# https://asturiasconvivencias.es/eventos
# --------------------------

